---
title: "NeMo: 3D Neural Motion Fields from Multiple Video Instances of the Same Action"
collection: publications
permalink: /publication/2023-06-18-nemo
excerpt: 'We aim to bridge the gap between monocular human mesh recovery (HMR) methods and multi-view MoCap systems by leveraging information shared across multiple video instances of the same action.  To achieve this, we introduce the Neural Motion (NeMo) field which is optimized to represent the underlying 3D motions across a set of videos of the same action. Empirically, we show that NeMo can recover 3D motion in sports using videos from both the Penn Action dataset and a MoCap dataset we collected mimicking actions in Penn Action, and show that NeMo achieves better 3D reconstruction compared to various baselines.'
date: 2023-07-18
venue: 'Conference on Computer Vision and Pattern Recognition (CVPR)'
paperurl: 'https://openaccess.thecvf.com/content/CVPR2023/html/Wang_NeMo_Learning_3D_Neural_Motion_Fields_From_Multiple_Video_Instances_CVPR_2023_paper.html'
citation: 'Wang, Kuan-Chieh, et al. "NeMo: Learning 3D Neural Motion Fields From Multiple Video Instances of the Same Action." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.'
---
Abstract: The task of reconstructing 3D human motion has wide-ranging applications. The gold standard Motion capture (MoCap) systems are accurate but inaccessible to the general public due to their cost, hardware, and space constraints. In contrast, monocular human mesh recovery (HMR) methods are much more accessible than MoCap as they take single-view videos as inputs. Replacing the multi-view MoCap systems with a monocular HMR method would break the current barriers to collecting accurate 3D motion thus making exciting applications like motion analysis and motion-driven animation accessible to the general public. However, the performance of existing HMR methods degrades when the video contains challenging and dynamic motion that is not in existing MoCap datasets used for training. This reduces its appeal as dynamic motion is frequently the target in 3D motion recovery in the aforementioned applications. Our study aims to bridge the gap between monocular HMR and multi-view MoCap systems by leveraging information shared across multiple video instances of the same action. We introduce the Neural Motion (NeMo) field. It is optimized to represent the underlying 3D motions across a set of videos of the same action. Empirically, we show that NeMo can recover 3D motion in sports using videos from the Penn Action dataset, where NeMo outperforms existing HMR methods in terms of 2D keypoint detection. To further validate NeMo using 3D metrics, we collected a small MoCap dataset mimicking actions in Penn Action, and show that NeMo achieves better 3D reconstruction compared to various baselines.

[[Project page](https://sites.google.com/view/nemo-neural-motion-field/home)][[Download paper here](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_NeMo_Learning_3D_Neural_Motion_Fields_From_Multiple_Video_Instances_CVPR_2023_paper.html)][[Code & Data](https://github.com/wangkua1/nemo-cvpr2023)]

Recommended citation: Wang, Kuan-Chieh, et al. "NeMo: Learning 3D Neural Motion Fields From Multiple Video Instances of the Same Action." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.
